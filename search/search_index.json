{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Multi-Agent Generator","text":"<p>Multi-Agent Generator is a powerful low-code/no-code tool that transforms plain English instructions into fully configured multi-agent AI teams. No scripting. No complexity. Just describe what you want, and let it build the agents.</p> <p>Frameworks supported: CrewAI, CrewAI Flow, LangGraph, Agno, ReAct (Classic + LCEL). LLM providers supported: Any provider via LiteLLM (OpenAI, IBM WatsonX, Ollama, Anthropic, etc.).</p>"},{"location":"#whats-new-in-v100","title":"What's New in v1.0.0","text":"<ul> <li>Tool Auto-Discovery &amp; Generation - 15+ pre-built tools + natural language tool creation</li> <li>Multi-Agent Orchestration Patterns - Supervisor, Debate, Voting, Pipeline, MapReduce</li> <li>Evaluation &amp; Testing Framework - Auto-generated tests + output quality metrics</li> <li>Full CLI Support - CLI commands for tools, evaluation, and orchestration</li> </ul>"},{"location":"#features","title":"Features","text":""},{"location":"#core-features","title":"Core Features","text":"<ul> <li>Generate multi-agent workflows in multiple frameworks</li> <li>Provider-agnostic (LiteLLM under the hood)</li> <li>Streamlit-based UI for interactive generation</li> <li>CLI tool for quick workflows</li> <li>JSON + code output formats</li> <li>Extensible agent/task configuration</li> </ul>"},{"location":"#new-in-v100","title":"New in v1.0.0","text":"<ul> <li>Tool Registry - Browse and use 15+ pre-built tools across 10 categories</li> <li>Tool Generator - Create custom tools from natural language descriptions</li> <li>Orchestration Patterns - 5 battle-tested patterns for agent coordination</li> <li>Test Generator - Auto-generate pytest test suites for your agents</li> <li>Agent Evaluator - Measure output quality with 7 built-in metrics</li> <li>Benchmarking - Performance testing and comparison</li> <li>Full CLI Support - Complete command-line interface for all features</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation</li> <li>Usage</li> <li>Tools</li> <li>Orchestration</li> <li>Evaluation</li> <li>Frameworks</li> <li>LLM Providers</li> <li>Examples</li> <li>API Reference</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API reference for the Multi-Agent Generator library.</p>"},{"location":"api-reference/#core-module","title":"Core Module","text":""},{"location":"api-reference/#generate_agents","title":"generate_agents","text":"<p>Generate agent code from a natural language prompt.</p> <pre><code>from multi_agent_generator import generate_agents\n\nresult = generate_agents(\n    prompt: str,           # Natural language description\n    framework: str,        # Target framework\n    provider: str = \"openai\",  # LLM provider\n    format: str = \"both\"   # Output format: \"code\", \"json\", or \"both\"\n) -&gt; dict\n</code></pre> <p>Returns:</p> <pre><code>{\n    \"code\": str,      # Generated Python code\n    \"config\": dict,   # Agent configuration\n    \"framework\": str  # Framework used\n}\n</code></pre>"},{"location":"api-reference/#tools-module","title":"Tools Module","text":"<pre><code>from multi_agent_generator.tools import (\n    ToolRegistry,\n    ToolGenerator,\n    ToolCategory,\n    ToolDefinition,\n)\n</code></pre>"},{"location":"api-reference/#toolregistry","title":"ToolRegistry","text":"<p>Registry of pre-built tools.</p> Method Parameters Returns Description <code>get_categories()</code> - <code>List[ToolCategory]</code> List all tool categories <code>get_tools_by_category(category)</code> <code>category: ToolCategory</code> <code>List[ToolDefinition]</code> Get tools in category <code>get_tool(name)</code> <code>name: str</code> <code>ToolDefinition</code> Get tool by name <code>list_all_tools()</code> - <code>List[ToolDefinition]</code> List all tools <code>search_tools(query)</code> <code>query: str</code> <code>List[ToolDefinition]</code> Search tools by keyword"},{"location":"api-reference/#toolgenerator","title":"ToolGenerator","text":"<p>Generate custom tools from descriptions.</p> Method Parameters Returns Description <code>generate_tool(description)</code> <code>description: str</code> <code>ToolDefinition</code> Generate from natural language <code>generate_from_template(template, **kwargs)</code> <code>template: str, **kwargs</code> <code>ToolDefinition</code> Generate from template <code>validate_tool(tool)</code> <code>tool: ToolDefinition</code> <code>bool</code> Validate tool code"},{"location":"api-reference/#toolcategory-enum","title":"ToolCategory (Enum)","text":"<pre><code>class ToolCategory(Enum):\n    WEB_SEARCH = \"web_search\"\n    FILE_OPERATIONS = \"file_operations\"\n    DATA_PROCESSING = \"data_processing\"\n    CODE_EXECUTION = \"code_execution\"\n    API_INTEGRATION = \"api_integration\"\n    DATABASE = \"database\"\n    COMMUNICATION = \"communication\"\n    MATH_CALCULATION = \"math_calculation\"\n    TEXT_PROCESSING = \"text_processing\"\n    IMAGE_PROCESSING = \"image_processing\"\n    CUSTOM = \"custom\"\n</code></pre>"},{"location":"api-reference/#tooldefinition-dataclass","title":"ToolDefinition (DataClass)","text":"<pre><code>@dataclass\nclass ToolDefinition:\n    name: str                    # Tool name\n    description: str             # Tool description\n    category: ToolCategory       # Tool category\n    parameters: Dict[str, Any]   # Input parameters schema\n    returns: str                 # Return type description\n    code: str                    # Python implementation\n</code></pre>"},{"location":"api-reference/#orchestration-module","title":"Orchestration Module","text":"<pre><code>from multi_agent_generator.orchestration import (\n    Orchestrator,\n    PatternType,\n    SupervisorPattern,\n    DebatePattern,\n    VotingPattern,\n    PipelinePattern,\n    MapReducePattern,\n)\n</code></pre>"},{"location":"api-reference/#orchestrator","title":"Orchestrator","text":"<p>High-level orchestration interface.</p> Method Parameters Returns Description <code>generate_from_description(description)</code> <code>description: str</code> <code>dict</code> Generate from natural language <code>create_pattern_config(pattern_type, agents, task_description, **kwargs)</code> Various <code>dict</code> Create pattern configuration <code>generate_code(config)</code> <code>config: dict</code> <code>str</code> Generate executable code <code>list_patterns()</code> - <code>List[PatternType]</code> List available patterns"},{"location":"api-reference/#patterntype-enum","title":"PatternType (Enum)","text":"<pre><code>class PatternType(Enum):\n    SUPERVISOR = \"supervisor\"\n    DEBATE = \"debate\"\n    VOTING = \"voting\"\n    PIPELINE = \"pipeline\"\n    MAP_REDUCE = \"map_reduce\"\n</code></pre>"},{"location":"api-reference/#pattern-classes","title":"Pattern Classes","text":""},{"location":"api-reference/#supervisorpattern","title":"SupervisorPattern","text":"<pre><code>SupervisorPattern(\n    supervisor_name: str,\n    worker_agents: List[str],\n    delegation_rules: Optional[Dict] = None\n)\n</code></pre>"},{"location":"api-reference/#debatepattern","title":"DebatePattern","text":"<pre><code>DebatePattern(\n    debaters: List[str],\n    moderator: str,\n    max_rounds: int = 3\n)\n</code></pre>"},{"location":"api-reference/#votingpattern","title":"VotingPattern","text":"<pre><code>VotingPattern(\n    voters: List[str],\n    voting_method: str = \"majority\"  # \"majority\", \"weighted\", \"ranked\"\n)\n</code></pre>"},{"location":"api-reference/#pipelinepattern","title":"PipelinePattern","text":"<pre><code>PipelinePattern(\n    stages: List[str],\n    error_handling: str = \"stop\"  # \"stop\", \"skip\", \"retry\"\n)\n</code></pre>"},{"location":"api-reference/#mapreducepattern","title":"MapReducePattern","text":"<pre><code>MapReducePattern(\n    mappers: List[str],\n    reducer: str,\n    chunk_strategy: str = \"equal\"  # \"equal\", \"by_size\", \"by_topic\"\n)\n</code></pre>"},{"location":"api-reference/#evaluation-module","title":"Evaluation Module","text":"<pre><code>from multi_agent_generator.evaluation import (\n    TestGenerator,\n    TestCase,\n    TestSuite,\n    TestType,\n    AgentEvaluator,\n    EvaluationResult,\n    EvaluationConfig,\n    Benchmark,\n    BenchmarkResult,\n)\n</code></pre>"},{"location":"api-reference/#testgenerator","title":"TestGenerator","text":"<p>Generate test suites for agents.</p> Method Parameters Returns Description <code>generate_test_suite(agent_config, test_types)</code> <code>config: dict, types: List[str]</code> <code>TestSuite</code> Generate complete suite <code>generate_tests(agent_config, test_type)</code> <code>config: dict, type: TestType</code> <code>List[TestCase]</code> Generate specific tests"},{"location":"api-reference/#testtype-enum","title":"TestType (Enum)","text":"<pre><code>class TestType(Enum):\n    UNIT = \"unit\"\n    INTEGRATION = \"integration\"\n    E2E = \"e2e\"\n    PERFORMANCE = \"performance\"\n    RELIABILITY = \"reliability\"\n    QUALITY = \"quality\"\n</code></pre>"},{"location":"api-reference/#testsuite","title":"TestSuite","text":"<pre><code>class TestSuite:\n    tests: List[TestCase]\n\n    def save(self, directory: str) -&gt; None:\n        \"\"\"Save test files to directory.\"\"\"\n\n    def to_code(self) -&gt; str:\n        \"\"\"Get all tests as code string.\"\"\"\n</code></pre>"},{"location":"api-reference/#testcase","title":"TestCase","text":"<pre><code>@dataclass\nclass TestCase:\n    name: str\n    test_type: TestType\n    code: str\n    description: str\n</code></pre>"},{"location":"api-reference/#agentevaluator","title":"AgentEvaluator","text":"<p>Evaluate agent output quality.</p> Method Parameters Returns Description <code>evaluate(agent_output, expected_output, task_description, config)</code> Various <code>EvaluationResult</code> Evaluate single output <code>evaluate_batch(test_cases)</code> <code>List[dict]</code> <code>List[EvaluationResult]</code> Evaluate multiple outputs"},{"location":"api-reference/#evaluationconfig","title":"EvaluationConfig","text":"<pre><code>@dataclass\nclass EvaluationConfig:\n    metrics: List[str] = field(default_factory=lambda: [\n        \"relevance\", \"completeness\", \"coherence\", \n        \"accuracy\", \"conciseness\", \"format\", \"tone\"\n    ])\n    weights: Optional[Dict[str, float]] = None\n    threshold: float = 0.7\n</code></pre>"},{"location":"api-reference/#evaluationresult","title":"EvaluationResult","text":"<pre><code>@dataclass\nclass EvaluationResult:\n    overall_score: float      # 0.0 - 1.0\n    metrics: Dict[str, float] # Individual scores\n    feedback: str             # Detailed feedback\n    passed: bool              # Above threshold?\n</code></pre>"},{"location":"api-reference/#benchmark","title":"Benchmark","text":"<p>Performance benchmarking.</p> Method Parameters Returns Description <code>run(agent, test_cases, iterations)</code> Various <code>BenchmarkResult</code> Benchmark single agent <code>compare(agents, test_cases)</code> <code>Dict[str, Agent], List</code> <code>ComparisonResult</code> Compare multiple agents"},{"location":"api-reference/#benchmarkresult","title":"BenchmarkResult","text":"<pre><code>@dataclass\nclass BenchmarkResult:\n    avg_response_time: float    # milliseconds\n    p95_response_time: float    # 95th percentile\n    throughput: float           # requests/second\n    success_rate: float         # percentage\n    error_rate: float           # percentage\n    avg_quality_score: float    # 0.0 - 1.0\n</code></pre>"},{"location":"api-reference/#framework-generators","title":"Framework Generators","text":"<p>Individual framework code generators.</p> <pre><code>from multi_agent_generator.frameworks import (\n    create_crewai_code,\n    create_crewai_flow_code,\n    create_langgraph_code,\n    create_react_code,\n    create_react_lcel_code,\n    create_agno_code,\n)\n</code></pre> <p>Each function accepts a configuration dictionary and returns generated code:</p> <pre><code>code = create_crewai_code(config: dict) -&gt; str\n</code></pre>"},{"location":"evaluation/","title":"Evaluation &amp; Testing Framework","text":"<p>The Evaluation module helps you test your agents and measure output quality automatically.</p>"},{"location":"evaluation/#overview","title":"Overview","text":"<ul> <li>Test Generator - Auto-generate pytest test suites</li> <li>Agent Evaluator - Measure output quality with 7 metrics</li> <li>Benchmark - Performance testing and comparison</li> <li>CLI support - Evaluate agent outputs from the command line</li> </ul>"},{"location":"evaluation/#cli-usage","title":"CLI Usage","text":""},{"location":"evaluation/#basic-evaluation","title":"Basic Evaluation","text":"<p>Evaluate agent output quality directly from the command line:</p> <pre><code>multi-agent-generator --evaluate \\\n  --query \"What is machine learning?\" \\\n  --response \"Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed.\"\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udcca Evaluating agent output...\n\nEvaluation Results: \u2705 PASSED\n==================================================\nQuery: What is machine learning?\nResponse: Machine learning is a subset of artificial intelligence that enables computers to learn from data...\n\nMetrics:\n  \u2022 Relevance:        1.00\n  \u2022 Completeness:     0.50\n  \u2022 Coherence:        0.80\n  \u2022 Accuracy:         0.70\n  \u2022 Task Completion:  0.70\n  \u2022 Response Time:    0.00ms\n  \u2022 Token Count:      22\n\nOverall Score: 0.740 (threshold: 0.7)\n</code></pre>"},{"location":"evaluation/#with-expected-output","title":"With Expected Output","text":"<p>Provide an expected output for accuracy comparison:</p> <pre><code>multi-agent-generator --evaluate \\\n  --query \"Explain neural networks\" \\\n  --response \"Neural networks are computing systems inspired by biological neurons\" \\\n  --expected \"Neural networks are machine learning models inspired by the human brain\"\n</code></pre>"},{"location":"evaluation/#custom-threshold","title":"Custom Threshold","text":"<p>Set a custom passing threshold (default is 0.7):</p> <pre><code>multi-agent-generator --evaluate \\\n  --query \"What is AI?\" \\\n  --response \"AI stands for Artificial Intelligence\" \\\n  --threshold 0.8\n</code></pre> <p>Output (when below threshold):</p> <pre><code>\ud83d\udcca Evaluating agent output...\n\nEvaluation Results: \u274c FAILED\n==================================================\nQuery: What is AI?\nResponse: AI stands for Artificial Intelligence\n\nMetrics:\n  \u2022 Relevance:        0.70\n  \u2022 Completeness:     0.45\n  \u2022 Coherence:        0.90\n  \u2022 Accuracy:         0.80\n  \u2022 Task Completion:  0.50\n\nOverall Score: 0.670 (threshold: 0.8)\n\nFeedback:\n  \u2022 Response lacks detail and explanation\n  \u2022 Consider providing more context about AI capabilities\n</code></pre>"},{"location":"evaluation/#save-results-to-file","title":"Save Results to File","text":"<p>Save evaluation results as JSON:</p> <pre><code>multi-agent-generator --evaluate \\\n  --query \"Summarize machine learning\" \\\n  --response \"ML is a type of AI that learns from data\" \\\n  --output evaluation_results.json\n</code></pre> <p>Generated JSON:</p> <pre><code>{\n  \"query\": \"Summarize machine learning\",\n  \"response\": \"ML is a type of AI that learns from data\",\n  \"metrics\": {\n    \"relevance_score\": 0.85,\n    \"completeness_score\": 0.70,\n    \"coherence_score\": 0.90,\n    \"accuracy_score\": 0.80,\n    \"response_time_ms\": 0.0,\n    \"token_count\": 10,\n    \"task_completion_rate\": 0.75,\n    \"overall_score\": 0.800\n  },\n  \"passed\": true,\n  \"feedback\": [\"Response is relevant but could be more comprehensive\"],\n  \"errors\": []\n}\n</code></pre>"},{"location":"evaluation/#evaluation-metrics-explained","title":"Evaluation Metrics Explained","text":"Metric Description CLI Display Relevance How relevant is the output to the query <code>Relevance: 0.XX</code> Completeness Does it cover all required aspects <code>Completeness: 0.XX</code> Coherence Is the output logically structured <code>Coherence: 0.XX</code> Accuracy Factual correctness <code>Accuracy: 0.XX</code> Task Completion Did it fulfill the request <code>Task Completion: 0.XX</code> Response Time Processing time in milliseconds <code>Response Time: X.XXms</code> Token Count Number of tokens in response <code>Token Count: XX</code>"},{"location":"evaluation/#test-generator","title":"Test Generator","text":""},{"location":"evaluation/#quick-start","title":"Quick Start","text":"<pre><code>from multi_agent_generator.evaluation import TestGenerator\n\ntest_gen = TestGenerator()\n\n# Generate a complete test suite\ntest_suite = test_gen.generate_test_suite(\n    agent_config=your_config,\n    test_types=[\"unit\", \"integration\", \"e2e\"]\n)\n\n# Save to files\ntest_suite.save(\"tests/\")\n</code></pre>"},{"location":"evaluation/#test-types","title":"Test Types","text":"Type Description What It Tests Unit Individual component testing Single agent functions Integration Multi-agent interaction Agent communication E2E (End-to-End) Full workflow validation Complete pipelines Performance Response time &amp; throughput Speed and efficiency Reliability Error handling &amp; recovery Edge cases and failures Quality Output quality metrics Content accuracy"},{"location":"evaluation/#generating-specific-tests","title":"Generating Specific Tests","text":"<pre><code>from multi_agent_generator.evaluation import TestGenerator, TestType\n\ntest_gen = TestGenerator()\n\n# Generate only unit tests\nunit_tests = test_gen.generate_tests(\n    agent_config=config,\n    test_type=TestType.UNIT\n)\n\n# Generate performance tests\nperf_tests = test_gen.generate_tests(\n    agent_config=config,\n    test_type=TestType.PERFORMANCE,\n    options={\n        \"iterations\": 100,\n        \"timeout\": 30\n    }\n)\n</code></pre>"},{"location":"evaluation/#generated-test-example","title":"Generated Test Example","text":"<pre><code># Generated test file: test_research_agent.py\nimport pytest\nfrom your_module import ResearchAgent\n\nclass TestResearchAgent:\n    \"\"\"Unit tests for ResearchAgent.\"\"\"\n\n    @pytest.fixture\n    def agent(self):\n        return ResearchAgent()\n\n    def test_agent_initialization(self, agent):\n        \"\"\"Test agent initializes correctly.\"\"\"\n        assert agent is not None\n        assert agent.role == \"Researcher\"\n\n    def test_agent_responds_to_query(self, agent):\n        \"\"\"Test agent responds to basic query.\"\"\"\n        response = agent.run(\"What is AI?\")\n        assert response is not None\n        assert len(response) &gt; 0\n\n    def test_agent_handles_empty_input(self, agent):\n        \"\"\"Test agent handles empty input gracefully.\"\"\"\n        with pytest.raises(ValueError):\n            agent.run(\"\")\n</code></pre>"},{"location":"evaluation/#agent-evaluator","title":"Agent Evaluator","text":""},{"location":"evaluation/#quick-start_1","title":"Quick Start","text":"<pre><code>from multi_agent_generator.evaluation import AgentEvaluator\n\nevaluator = AgentEvaluator()\n\nresult = evaluator.evaluate(\n    agent_output=\"The market analysis shows growth of 15%...\",\n    expected_output=\"Market trends indicate positive growth...\",\n    task_description=\"Analyze Q4 sales data\"\n)\n\nprint(f\"Overall Score: {result.overall_score}\")  # 0.0 - 1.0\nprint(f\"Metrics: {result.metrics}\")\n</code></pre>"},{"location":"evaluation/#evaluation-metrics","title":"Evaluation Metrics","text":"Metric Description Range Relevance How relevant is the output to the task 0.0 - 1.0 Completeness Does it cover all required aspects 0.0 - 1.0 Coherence Is the output logically structured 0.0 - 1.0 Accuracy Factual correctness (when verifiable) 0.0 - 1.0 Conciseness Appropriate length without redundancy 0.0 - 1.0 Format Follows expected format/structure 0.0 - 1.0 Tone Appropriate tone for the context 0.0 - 1.0"},{"location":"evaluation/#detailed-evaluation","title":"Detailed Evaluation","text":"<pre><code>from multi_agent_generator.evaluation import AgentEvaluator, EvaluationConfig\n\nevaluator = AgentEvaluator()\n\n# Configure which metrics to use\nconfig = EvaluationConfig(\n    metrics=[\"relevance\", \"completeness\", \"accuracy\"],\n    weights={\n        \"relevance\": 0.4,\n        \"completeness\": 0.3,\n        \"accuracy\": 0.3\n    }\n)\n\nresult = evaluator.evaluate(\n    agent_output=output,\n    expected_output=expected,\n    task_description=task,\n    config=config\n)\n\n# Access individual metrics\nprint(result.metrics[\"relevance\"])\nprint(result.metrics[\"completeness\"])\nprint(result.metrics[\"accuracy\"])\n</code></pre>"},{"location":"evaluation/#batch-evaluation","title":"Batch Evaluation","text":"<pre><code>from multi_agent_generator.evaluation import AgentEvaluator\n\nevaluator = AgentEvaluator()\n\n# Evaluate multiple outputs\ntest_cases = [\n    {\"output\": \"...\", \"expected\": \"...\", \"task\": \"...\"},\n    {\"output\": \"...\", \"expected\": \"...\", \"task\": \"...\"},\n]\n\nresults = evaluator.evaluate_batch(test_cases)\n\n# Get aggregate statistics\navg_score = sum(r.overall_score for r in results) / len(results)\nprint(f\"Average Score: {avg_score}\")\n</code></pre>"},{"location":"evaluation/#benchmark","title":"Benchmark","text":""},{"location":"evaluation/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code>from multi_agent_generator.evaluation import Benchmark\n\nbenchmark = Benchmark()\n\n# Benchmark a single agent\nresults = benchmark.run(\n    agent=your_agent,\n    test_cases=test_cases,\n    iterations=10\n)\n\nprint(f\"Avg Response Time: {results.avg_response_time}ms\")\nprint(f\"Throughput: {results.throughput} req/s\")\nprint(f\"Success Rate: {results.success_rate}%\")\n</code></pre>"},{"location":"evaluation/#comparing-agents","title":"Comparing Agents","text":"<pre><code>from multi_agent_generator.evaluation import Benchmark\n\nbenchmark = Benchmark()\n\n# Compare multiple agents\ncomparison = benchmark.compare(\n    agents={\n        \"agent_v1\": agent_v1,\n        \"agent_v2\": agent_v2,\n    },\n    test_cases=test_cases\n)\n\n# View comparison report\nprint(comparison.summary())\n</code></pre>"},{"location":"evaluation/#benchmark-metrics","title":"Benchmark Metrics","text":"Metric Description <code>avg_response_time</code> Average time to respond (ms) <code>p95_response_time</code> 95th percentile response time <code>throughput</code> Requests per second <code>success_rate</code> Percentage of successful responses <code>error_rate</code> Percentage of errors <code>avg_quality_score</code> Average output quality"},{"location":"evaluation/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"evaluation/#running-tests-in-ci","title":"Running Tests in CI","text":"<pre><code># .github/workflows/test.yml\nname: Agent Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n      - run: pip install -e \".[dev]\"\n      - run: pytest tests/ -v\n</code></pre>"},{"location":"evaluation/#quality-gates","title":"Quality Gates","text":"<pre><code>from multi_agent_generator.evaluation import AgentEvaluator\n\nevaluator = AgentEvaluator()\nresult = evaluator.evaluate(output, expected, task)\n\n# Fail CI if quality is below threshold\nassert result.overall_score &gt;= 0.8, f\"Quality score {result.overall_score} below threshold\"\n</code></pre>"},{"location":"evaluation/#api-reference","title":"API Reference","text":""},{"location":"evaluation/#testgenerator","title":"TestGenerator","text":"Method Description <code>generate_test_suite(config, test_types)</code> Generate complete test suite <code>generate_tests(config, test_type)</code> Generate specific test type"},{"location":"evaluation/#agentevaluator","title":"AgentEvaluator","text":"Method Description <code>evaluate(output, expected, task)</code> Evaluate single output <code>evaluate_batch(test_cases)</code> Evaluate multiple outputs"},{"location":"evaluation/#benchmark_1","title":"Benchmark","text":"Method Description <code>run(agent, test_cases, iterations)</code> Run benchmark on agent <code>compare(agents, test_cases)</code> Compare multiple agents"},{"location":"evaluation/#evaluationresult","title":"EvaluationResult","text":"Property Type Description <code>overall_score</code> float Overall quality score (0.0-1.0) <code>metrics</code> dict Individual metric scores <code>feedback</code> str Detailed feedback text <code>passed</code> bool Whether it passed threshold"},{"location":"examples/","title":"Examples","text":"<p>This page contains practical examples for all major features of multi-agent-generator.</p>"},{"location":"examples/#agent-generation-examples","title":"Agent Generation Examples","text":""},{"location":"examples/#research-assistant","title":"Research Assistant","text":"<p>Prompt:</p> <pre><code>I need a research assistant that summarizes papers and answers questions\n</code></pre> <p>Command:</p> <pre><code>multi-agent-generator \"I need a research assistant that summarizes papers and answers questions\" --framework crewai --output researcher.py\n</code></pre>"},{"location":"examples/#content-creation-team","title":"Content Creation Team","text":"<p>Prompt:</p> <pre><code>I need a team to create viral social media content and manage our brand presence\n</code></pre> <p>Command:</p> <pre><code>multi-agent-generator \"I need a team to create viral social media content and manage our brand presence\" --framework langgraph --output content_team.py\n</code></pre>"},{"location":"examples/#customer-support-langgraph","title":"Customer Support (LangGraph)","text":"<p>Prompt:</p> <pre><code>Build me a LangGraph workflow for customer support with routing and escalation\n</code></pre> <p>Command:</p> <pre><code>multi-agent-generator \"Build me a LangGraph workflow for customer support with routing and escalation\" --framework langgraph --output support.py\n</code></pre>"},{"location":"examples/#data-analysis-pipeline","title":"Data Analysis Pipeline","text":"<p>Prompt:</p> <pre><code>Create a data analysis team with a collector, processor, and reporter\n</code></pre> <p>Command:</p> <pre><code>multi-agent-generator \"Create a data analysis team with a collector, processor, and reporter\" --framework crewai-flow --output data_pipeline.py\n</code></pre>"},{"location":"examples/#tool-discovery-examples","title":"Tool Discovery Examples","text":""},{"location":"examples/#browse-pre-built-tools","title":"Browse Pre-built Tools","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry\n\nregistry = ToolRegistry()\n\n# List all categories\nfor category in registry.get_categories():\n    print(f\"Category: {category}\")\n    for tool in registry.get_tools_by_category(category):\n        print(f\"  - {tool.name}: {tool.description}\")\n</code></pre>"},{"location":"examples/#get-tool-code-for-a-framework","title":"Get Tool Code for a Framework","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry\n\nregistry = ToolRegistry()\ntool = registry.get_tool(\"tavily_search\")\n\n# Get CrewAI-compatible code\ncrewai_code = tool.get_code(\"crewai\")\nprint(crewai_code)\n\n# Get LangGraph-compatible code\nlanggraph_code = tool.get_code(\"langgraph\")\nprint(langgraph_code)\n</code></pre>"},{"location":"examples/#generate-custom-tools","title":"Generate Custom Tools","text":"<pre><code>from multi_agent_generator.tools import ToolGenerator\n\ngenerator = ToolGenerator()\n\n# From description\ntool = generator.generate_tool(\n    \"Create a tool that fetches stock prices from Yahoo Finance\"\n)\nprint(tool.code)\nprint(tool.dependencies)\n\n# Generate multiple tools from a task\ntools = generator.generate_tools_for_task(\n    \"Build a financial analysis agent\",\n    max_tools=5\n)\nfor tool in tools:\n    print(f\"- {tool.name}: {tool.description}\")\n</code></pre>"},{"location":"examples/#orchestration-pattern-examples","title":"Orchestration Pattern Examples","text":""},{"location":"examples/#supervisor-pattern","title":"Supervisor Pattern","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.SUPERVISOR,\n    agents=[\"researcher\", \"writer\", \"reviewer\"],\n    task_description=\"Write a comprehensive market analysis report\"\n)\n\ncode = orchestrator.generate_code(config, framework=\"langgraph\")\nprint(code)\n</code></pre>"},{"location":"examples/#debate-pattern","title":"Debate Pattern","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.DEBATE,\n    agents=[\"optimist\", \"pessimist\", \"moderator\"],\n    task_description=\"Evaluate the investment opportunity\",\n    debate_rounds=3\n)\n\ncode = orchestrator.generate_code(config, framework=\"crewai\")\nprint(code)\n</code></pre>"},{"location":"examples/#voting-pattern","title":"Voting Pattern","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.VOTING,\n    agents=[\"analyst_1\", \"analyst_2\", \"analyst_3\"],\n    task_description=\"Classify customer feedback sentiment\",\n    voting_threshold=0.6\n)\n\ncode = orchestrator.generate_code(config, framework=\"langgraph\")\nprint(code)\n</code></pre>"},{"location":"examples/#pipeline-pattern","title":"Pipeline Pattern","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.PIPELINE,\n    agents=[\"data_collector\", \"data_cleaner\", \"analyzer\", \"reporter\"],\n    task_description=\"Process and analyze sales data\"\n)\n\ncode = orchestrator.generate_code(config, framework=\"crewai-flow\")\nprint(code)\n</code></pre>"},{"location":"examples/#map-reduce-pattern","title":"Map-Reduce Pattern","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.MAP_REDUCE,\n    agents=[\"mapper_1\", \"mapper_2\", \"mapper_3\", \"reducer\"],\n    task_description=\"Analyze customer reviews across regions\"\n)\n\ncode = orchestrator.generate_code(config, framework=\"langgraph\")\nprint(code)\n</code></pre>"},{"location":"examples/#generate-from-description","title":"Generate from Description","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator\n\norchestrator = Orchestrator()\n\n# Let the system choose the best pattern\nresult = orchestrator.generate_from_description(\n    \"I need agents that vote on the best marketing strategy\"\n)\n\nprint(f\"Selected pattern: {result['pattern']}\")\nprint(result['code'])\n</code></pre>"},{"location":"examples/#evaluation-examples","title":"Evaluation Examples","text":""},{"location":"examples/#generate-unit-tests","title":"Generate Unit Tests","text":"<pre><code>from multi_agent_generator.evaluation import TestGenerator\n\ntest_gen = TestGenerator()\n\nagent_config = {\n    \"agents\": [\n        {\"name\": \"researcher\", \"role\": \"Research Specialist\"},\n        {\"name\": \"writer\", \"role\": \"Content Writer\"}\n    ],\n    \"tasks\": [\n        {\"name\": \"research_task\", \"description\": \"Research the topic\"},\n        {\"name\": \"write_task\", \"description\": \"Write the article\"}\n    ]\n}\n\ntest_suite = test_gen.generate_test_suite(\n    agent_config=agent_config,\n    test_types=[\"unit\", \"integration\"]\n)\n\n# Save tests to directory\ntest_suite.save(\"tests/\")\nprint(f\"Generated {len(test_suite.tests)} tests\")\n</code></pre>"},{"location":"examples/#evaluate-agent-output","title":"Evaluate Agent Output","text":"<pre><code>from multi_agent_generator.evaluation import AgentEvaluator\n\nevaluator = AgentEvaluator()\n\nresult = evaluator.evaluate(\n    agent_output=\"The quarterly analysis shows a 15% increase in revenue...\",\n    expected_output=\"Revenue increased by approximately 15% this quarter...\",\n    task_description=\"Analyze Q4 financial performance\"\n)\n\nprint(f\"Overall Score: {result.overall_score}\")\nprint(f\"Relevance: {result.relevance_score}\")\nprint(f\"Completeness: {result.completeness_score}\")\nprint(f\"Accuracy: {result.accuracy_score}\")\n</code></pre>"},{"location":"examples/#run-benchmarks","title":"Run Benchmarks","text":"<pre><code>from multi_agent_generator.evaluation import Benchmark\n\nbenchmark = Benchmark()\n\n# Define test cases\ntest_cases = [\n    {\n        \"input\": \"Summarize the Q4 earnings report\",\n        \"expected\": \"Q4 earnings showed growth...\"\n    },\n    {\n        \"input\": \"Compare product A vs product B\",\n        \"expected\": \"Product A excels in...\"\n    }\n]\n\n# Run benchmark\nresults = benchmark.run(\n    agent_function=your_agent.run,\n    test_cases=test_cases,\n    metrics=[\"latency\", \"accuracy\", \"relevance\"]\n)\n\n# Generate report\nreport = benchmark.generate_report(results)\nprint(report)\n</code></pre>"},{"location":"examples/#compare-frameworks","title":"Compare Frameworks","text":"<pre><code>from multi_agent_generator.evaluation import Benchmark\n\nbenchmark = Benchmark()\n\n# Compare the same prompt across frameworks\ncomparison = benchmark.compare_frameworks(\n    prompt=\"Build a customer support agent\",\n    frameworks=[\"crewai\", \"langgraph\", \"react\"],\n    metrics=[\"code_quality\", \"execution_time\"]\n)\n\nfor framework, scores in comparison.items():\n    print(f\"{framework}: {scores}\")\n</code></pre>"},{"location":"examples/#complete-workflow-example","title":"Complete Workflow Example","text":"<p>Here's a complete example combining all features:</p> <pre><code>from multi_agent_generator import generate_agents\nfrom multi_agent_generator.tools import ToolRegistry, ToolGenerator\nfrom multi_agent_generator.orchestration import Orchestrator, PatternType\nfrom multi_agent_generator.evaluation import TestGenerator, AgentEvaluator\n\n# 1. Discover and select tools\nregistry = ToolRegistry()\nweb_tools = registry.get_tools_by_category(\"web_search\")\nfile_tools = registry.get_tools_by_category(\"file_operations\")\n\n# 2. Generate custom tool if needed\ntool_gen = ToolGenerator()\ncustom_tool = tool_gen.generate_tool(\n    \"Create a tool that fetches company financial data from SEC EDGAR\"\n)\n\n# 3. Configure orchestration pattern\norchestrator = Orchestrator()\npattern_config = orchestrator.create_pattern_config(\n    pattern_type=PatternType.PIPELINE,\n    agents=[\"data_gatherer\", \"analyzer\", \"report_writer\"],\n    task_description=\"Analyze company financials and write report\"\n)\n\n# 4. Generate the agent code\nresult = generate_agents(\n    prompt=\"Build a financial analysis team\",\n    framework=\"langgraph\",\n    provider=\"openai\"\n)\n\n# Save the generated code\nwith open(\"financial_team.py\", \"w\") as f:\n    f.write(result[\"code\"])\n\n# 5. Generate tests\ntest_gen = TestGenerator()\ntest_suite = test_gen.generate_test_suite(\n    agent_config=result[\"config\"],\n    test_types=[\"unit\", \"integration\", \"edge_case\"]\n)\ntest_suite.save(\"tests/\")\n\n# 6. Set up evaluation\nevaluator = AgentEvaluator()\n\n# Ready to run and evaluate\nprint(\"Agent team generated successfully\")\nprint(f\"Tools available: {len(web_tools) + len(file_tools) + 1}\")\nprint(f\"Tests generated: {len(test_suite.tests)}\")\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#basic-installation","title":"Basic Installation","text":"<pre><code>pip install multi-agent-generator\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<pre><code>git clone https://github.com/aakriti1318/multi-agent-generator.git\ncd multi-agent-generator\npip install -e \".[dev]\"\n</code></pre>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>At least one supported LLM provider (OpenAI, WatsonX, Ollama, etc.)</li> </ul>"},{"location":"installation/#environment-variables","title":"Environment Variables","text":"<p>Set up environment variables for your chosen LLM provider:</p>"},{"location":"installation/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-openai-api-key\"\n</code></pre>"},{"location":"installation/#ibm-watsonx","title":"IBM WatsonX","text":"<pre><code>export WATSONX_API_KEY=\"your-watsonx-api-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"\n</code></pre>"},{"location":"installation/#ollama-local","title":"Ollama (Local)","text":"<pre><code>export OLLAMA_URL=\"http://localhost:11434\"\n</code></pre>"},{"location":"installation/#generic-litellm","title":"Generic LiteLLM","text":"<pre><code>export API_KEY=\"your-api-key\"\nexport API_BASE=\"https://your-api-endpoint\"\n</code></pre>"},{"location":"installation/#provider-notes","title":"Provider Notes","text":"<ul> <li>Agno currently only works with <code>OPENAI_API_KEY</code> without tools. Support for additional APIs and tools will be expanded in future releases.</li> </ul> <p>You can freely switch providers using <code>--provider</code> in CLI or by setting environment variables.</p>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify everything works:</p> <pre><code># Check CLI is available\nmulti-agent-generator --help\n\n# Test a simple generation\nmulti-agent-generator \"Create a simple assistant\" --framework crewai\n</code></pre>"},{"location":"installation/#optional-streamlit-ui","title":"Optional: Streamlit UI","text":"<p>The Streamlit UI is included by default. Launch it with:</p> <pre><code>streamlit run streamlit_app.py\n</code></pre>"},{"location":"llm-providers/","title":"LLM Providers","text":"<p>Multi-Agent Generator supports multiple LLM providers through LiteLLM, making it easy to switch between providers.</p>"},{"location":"llm-providers/#supported-providers","title":"Supported Providers","text":"Provider Models Default Model OpenAI GPT-4, GPT-4o, GPT-3.5 gpt-4o-mini IBM WatsonX Llama 3, Granite llama-3-70b-instruct Ollama Llama, Mistral, CodeLlama llama3 Anthropic Claude 3, Claude 2 claude-3-sonnet Azure OpenAI GPT-4, GPT-3.5 gpt-4 Google Gemini Pro, PaLM gemini-pro Cohere Command, Command-Light command"},{"location":"llm-providers/#configuration","title":"Configuration","text":""},{"location":"llm-providers/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider openai\n</code></pre> <p>Available Models: - <code>gpt-4o</code> - Latest GPT-4 optimized - <code>gpt-4o-mini</code> - Smaller, faster GPT-4 (default) - <code>gpt-4-turbo</code> - GPT-4 with vision - <code>gpt-3.5-turbo</code> - Fast and cost-effective</p>"},{"location":"llm-providers/#ibm-watsonx","title":"IBM WatsonX","text":"<pre><code>export WATSONX_API_KEY=\"your-api-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider watsonx\n</code></pre> <p>Available Models: - <code>llama-3-70b-instruct</code> - Llama 3 70B (default) - <code>llama-3-8b-instruct</code> - Llama 3 8B - <code>granite-13b-chat-v2</code> - IBM Granite - <code>mixtral-8x7b-instruct</code> - Mixtral</p>"},{"location":"llm-providers/#ollama-local","title":"Ollama (Local)","text":"<p>Run models locally with Ollama:</p> <pre><code># Install Ollama\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull a model\nollama pull llama3\n\n# Set environment\nexport OLLAMA_URL=\"http://localhost:11434\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider ollama\n</code></pre> <p>Available Models: - <code>llama3</code> - Llama 3 (default) - <code>llama3:70b</code> - Llama 3 70B - <code>mistral</code> - Mistral 7B - <code>codellama</code> - Code Llama - <code>mixtral</code> - Mixtral 8x7B</p>"},{"location":"llm-providers/#anthropic","title":"Anthropic","text":"<pre><code>export ANTHROPIC_API_KEY=\"sk-ant-...\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider anthropic\n</code></pre> <p>Available Models: - <code>claude-3-opus</code> - Most capable - <code>claude-3-sonnet</code> - Balanced (default) - <code>claude-3-haiku</code> - Fast and efficient</p>"},{"location":"llm-providers/#azure-openai","title":"Azure OpenAI","text":"<pre><code>export AZURE_API_KEY=\"your-key\"\nexport AZURE_API_BASE=\"https://your-resource.openai.azure.com\"\nexport AZURE_API_VERSION=\"2024-02-01\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider azure\n</code></pre>"},{"location":"llm-providers/#google-vertex-ai-gemini","title":"Google (Vertex AI / Gemini)","text":"<pre><code>export GOOGLE_API_KEY=\"your-api-key\"\n# Or for Vertex AI\nexport GOOGLE_APPLICATION_CREDENTIALS=\"path/to/credentials.json\"\n</code></pre> <pre><code>multi-agent-generator \"Your prompt\" --provider google\n</code></pre> <p>Available Models: - <code>gemini-pro</code> - Gemini Pro (default) - <code>gemini-pro-vision</code> - With vision capabilities</p>"},{"location":"llm-providers/#switching-providers","title":"Switching Providers","text":""},{"location":"llm-providers/#cli","title":"CLI","text":"<p>Use the <code>--provider</code> flag:</p> <pre><code># OpenAI (default)\nmulti-agent-generator \"prompt\" --framework crewai\n\n# WatsonX\nmulti-agent-generator \"prompt\" --framework crewai --provider watsonx\n\n# Ollama\nmulti-agent-generator \"prompt\" --framework crewai --provider ollama\n\n# Anthropic\nmulti-agent-generator \"prompt\" --framework crewai --provider anthropic\n</code></pre>"},{"location":"llm-providers/#python-api","title":"Python API","text":"<pre><code>from multi_agent_generator import generate_agents\n\n# OpenAI\nresult = generate_agents(prompt, framework=\"crewai\", provider=\"openai\")\n\n# WatsonX\nresult = generate_agents(prompt, framework=\"crewai\", provider=\"watsonx\")\n\n# Ollama\nresult = generate_agents(prompt, framework=\"crewai\", provider=\"ollama\")\n</code></pre>"},{"location":"llm-providers/#streamlit-ui","title":"Streamlit UI","text":"<p>Select the provider from the dropdown in the sidebar.</p>"},{"location":"llm-providers/#custom-models","title":"Custom Models","text":""},{"location":"llm-providers/#specifying-a-model","title":"Specifying a Model","text":"<pre><code>from multi_agent_generator import generate_agents\n\nresult = generate_agents(\n    prompt=\"Your prompt\",\n    framework=\"crewai\",\n    provider=\"openai\",\n    model=\"gpt-4-turbo\"  # Specify model\n)\n</code></pre>"},{"location":"llm-providers/#using-litellm-directly","title":"Using LiteLLM Directly","text":"<p>For advanced use cases, access LiteLLM directly:</p> <pre><code>import litellm\n\nresponse = litellm.completion(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n)\n</code></pre>"},{"location":"llm-providers/#provider-comparison","title":"Provider Comparison","text":"Provider Speed Cost Quality Local OpenAI GPT-4o Fast $$ Excellent No WatsonX Llama Medium $$ Very Good No Ollama Varies Free Good Yes Anthropic Claude Fast $$$ Excellent No Google Gemini Fast $ Very Good No"},{"location":"llm-providers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"llm-providers/#api-key-issues","title":"API Key Issues","text":"<pre><code># Verify API key is set\necho $OPENAI_API_KEY\n\n# Test with a simple call\npython -c \"import litellm; print(litellm.completion(model='gpt-4o-mini', messages=[{'role':'user','content':'hi'}]))\"\n</code></pre>"},{"location":"llm-providers/#rate-limits","title":"Rate Limits","text":"<p>If you hit rate limits, consider: - Using a different model (e.g., gpt-3.5-turbo) - Adding delays between requests - Using a local model with Ollama</p>"},{"location":"llm-providers/#connection-issues","title":"Connection Issues","text":"<p>For Ollama:</p> <pre><code># Check Ollama is running\ncurl http://localhost:11434/api/tags\n\n# Restart Ollama\nollama serve\n</code></pre>"},{"location":"llm-providers/#provider-not-found","title":"Provider Not Found","text":"<p>Ensure you have the correct provider name: - <code>openai</code> (not \"OpenAI\") - <code>watsonx</code> (not \"ibm\" or \"watson\") - <code>ollama</code> (not \"local\") - <code>anthropic</code> (not \"claude\")</p>"},{"location":"orchestration/","title":"Multi-Agent Orchestration Patterns","text":"<p>The Orchestration module provides battle-tested patterns for coordinating multiple agents to work together effectively.</p>"},{"location":"orchestration/#overview","title":"Overview","text":"<p>Choose from 5 orchestration patterns based on your use case:</p> Pattern Best For Description Supervisor Delegating tasks Central coordinator routes work to specialists Debate Reaching consensus Agents discuss and refine answers Voting Democratic decisions Agents vote on the best response Pipeline Sequential processing Chain of specialized processing steps MapReduce Parallel processing Split work, process in parallel, aggregate"},{"location":"orchestration/#cli-usage","title":"CLI Usage","text":""},{"location":"orchestration/#list-available-patterns","title":"List Available Patterns","text":"<p>See all orchestration patterns with descriptions and use cases:</p> <pre><code>multi-agent-generator --list-patterns\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udd04 Available Orchestration Patterns:\n\n  [SUPERVISOR PATTERN]\n    Description: A supervisor agent coordinates and delegates tasks to specialized worker agents\n    Use Cases:\n      \u2022 Project management workflows\n      \u2022 Quality assurance processes\n      \u2022 Customer service escalation\n\n  [DEBATE PATTERN]\n    Description: Multiple agents argue different perspectives and reach consensus through structured debate\n    Use Cases:\n      \u2022 Decision making processes\n      \u2022 Fact checking and verification\n      \u2022 Brainstorming sessions\n\n  [VOTING PATTERN]\n    Description: Multiple agents vote on decisions, with configurable voting rules\n    Use Cases:\n      \u2022 Ensemble AI decisions\n      \u2022 Content moderation\n      \u2022 Quality assessment\n\n  [PIPELINE PATTERN]\n    Description: Sequential processing chain where each agent transforms and passes data to the next\n    Use Cases:\n      \u2022 Content creation and editing\n      \u2022 Data transformation pipelines\n      \u2022 Multi-stage processing\n\n  [MAP-REDUCE PATTERN]\n    Description: Parallel processing where multiple agents work on chunks, then results are aggregated\n    Use Cases:\n      \u2022 Large document summarization\n      \u2022 Parallel data analysis\n      \u2022 Distributed processing\n</code></pre>"},{"location":"orchestration/#get-pattern-suggestion","title":"Get Pattern Suggestion","text":"<p>Describe your needs in natural language and get a recommended pattern:</p> <pre><code>multi-agent-generator --orchestrate \"I need a team where a manager assigns tasks to specialists\"\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udd04 Analyzing task description...\n   \"I need a team where a manager assigns tasks to specialists\"\n\n\ud83d\udccc Recommended pattern: supervisor\n\n\ud83c\udfd7\ufe0f  Generating supervisor orchestration code for langgraph...\n\n# Generated code follows...\n</code></pre>"},{"location":"orchestration/#generate-code-for-specific-pattern","title":"Generate Code for Specific Pattern","text":"<pre><code># Generate supervisor pattern\nmulti-agent-generator --pattern supervisor --framework langgraph\n\n# Generate debate pattern with CrewAI\nmulti-agent-generator --pattern debate --framework crewai\n\n# Generate voting pattern with 5 agents\nmulti-agent-generator --pattern voting --num-agents 5\n</code></pre>"},{"location":"orchestration/#save-to-file","title":"Save to File","text":"<pre><code>multi-agent-generator --pattern supervisor --framework langgraph --output supervisor_system.py\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udd04 Using orchestration pattern: supervisor\n\n\ud83c\udfd7\ufe0f  Generating supervisor orchestration code for langgraph...\n\n\u2705 Orchestration code saved to supervisor_system.py\n\n\ud83d\udccb Orchestration Summary:\n   Pattern: supervisor\n   Framework: langgraph\n   Agents: ['supervisor', 'worker_1', 'worker_2']\n</code></pre>"},{"location":"orchestration/#customize-number-of-agents","title":"Customize Number of Agents","text":"<pre><code># Generate with 5 agents instead of default 3\nmulti-agent-generator --pattern map_reduce --num-agents 5 --framework langgraph\n</code></pre>"},{"location":"orchestration/#pattern-framework-combinations","title":"Pattern + Framework Combinations","text":"Pattern LangGraph CrewAI CrewAI-Flow supervisor \u2705 \u2705 \u2705 debate \u2705 \u2705 \u2705 voting \u2705 \u2705 \u2705 pipeline \u2705 \u2705 \u2705 map_reduce \u2705 \u2705 \u2705"},{"location":"orchestration/#example-complete-workflow","title":"Example: Complete Workflow","text":"<pre><code># Step 1: See available patterns\nmulti-agent-generator --list-patterns\n\n# Step 2: Get suggestion for your use case\nmulti-agent-generator --orchestrate \"I need agents to review and improve a document collaboratively\"\n\n# Step 3: Generate the code\nmulti-agent-generator --pattern pipeline --framework langgraph --num-agents 4 --output document_pipeline.py\n</code></pre>"},{"location":"orchestration/#quick-start","title":"Quick Start","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\n# Generate from natural language\nresult = orchestrator.generate_from_description(\n    \"I need a research team where a manager delegates to specialists\"\n)\nprint(result[\"code\"])\n</code></pre>"},{"location":"orchestration/#patterns","title":"Patterns","text":""},{"location":"orchestration/#supervisor-pattern","title":"Supervisor Pattern","text":"<p>A central supervisor agent coordinates work among specialist agents.</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.SUPERVISOR,\n    agents=[\"researcher\", \"writer\", \"reviewer\"],\n    task_description=\"Create a comprehensive market analysis report\"\n)\n\ncode = orchestrator.generate_code(config)\n</code></pre> <p>Use Cases: - Task delegation and management - Quality control workflows - Hierarchical team structures</p> <p>How It Works: 1. Supervisor receives the task 2. Supervisor analyzes and delegates to appropriate specialist 3. Specialist completes subtask and reports back 4. Supervisor aggregates results or assigns next task</p>"},{"location":"orchestration/#debate-pattern","title":"Debate Pattern","text":"<p>Multiple agents discuss and refine an answer through structured debate.</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.DEBATE,\n    agents=[\"optimist\", \"pessimist\", \"moderator\"],\n    task_description=\"Evaluate the risks and benefits of a new product launch\",\n    max_rounds=3\n)\n\ncode = orchestrator.generate_code(config)\n</code></pre> <p>Use Cases: - Complex decision making - Risk assessment - Strategy evaluation</p> <p>How It Works: 1. Each agent presents their perspective 2. Agents critique and respond to each other 3. Moderator synthesizes final consensus 4. Process repeats for specified rounds</p>"},{"location":"orchestration/#voting-pattern","title":"Voting Pattern","text":"<p>Agents independently solve a problem, then vote on the best solution.</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.VOTING,\n    agents=[\"analyst_1\", \"analyst_2\", \"analyst_3\"],\n    task_description=\"Determine the best investment strategy\",\n    voting_method=\"majority\"  # or \"weighted\", \"ranked\"\n)\n\ncode = orchestrator.generate_code(config)\n</code></pre> <p>Use Cases: - Democratic decision making - Reducing individual bias - Ensemble approaches</p> <p>Voting Methods: - <code>majority</code> - Simple majority wins - <code>weighted</code> - Votes weighted by agent expertise - <code>ranked</code> - Ranked choice voting</p>"},{"location":"orchestration/#pipeline-pattern","title":"Pipeline Pattern","text":"<p>Agents process work sequentially, each adding their expertise.</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.PIPELINE,\n    agents=[\"data_collector\", \"analyzer\", \"report_writer\", \"reviewer\"],\n    task_description=\"Generate a quarterly business report\"\n)\n\ncode = orchestrator.generate_code(config)\n</code></pre> <p>Use Cases: - Content creation workflows - Data processing pipelines - Document review processes</p> <p>How It Works: 1. First agent processes input 2. Output passes to next agent 3. Each agent transforms and enriches 4. Final agent produces output</p>"},{"location":"orchestration/#mapreduce-pattern","title":"MapReduce Pattern","text":"<p>Split work across multiple agents, process in parallel, then aggregate.</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.MAP_REDUCE,\n    agents=[\"mapper_1\", \"mapper_2\", \"mapper_3\", \"reducer\"],\n    task_description=\"Analyze customer feedback from multiple sources\",\n    chunk_strategy=\"by_source\"  # or \"by_size\", \"by_topic\"\n)\n\ncode = orchestrator.generate_code(config)\n</code></pre> <p>Use Cases: - Large-scale data analysis - Parallel document processing - Distributed research tasks</p> <p>How It Works: 1. Input is split into chunks 2. Mapper agents process chunks in parallel 3. Reducer agent aggregates all results 4. Final output is synthesized</p>"},{"location":"orchestration/#natural-language-generation","title":"Natural Language Generation","text":"<p>Describe your orchestration needs in plain English:</p> <pre><code>from multi_agent_generator.orchestration import Orchestrator\n\norchestrator = Orchestrator()\n\n# The system automatically selects the best pattern\nresult = orchestrator.generate_from_description(\n    \"Build a content team with a supervisor managing writers and editors\"\n)\n\nprint(result[\"pattern\"])  # SUPERVISOR\nprint(result[\"agents\"])   # [\"supervisor\", \"writer\", \"editor\"]\nprint(result[\"code\"])     # Generated code\n</code></pre>"},{"location":"orchestration/#api-reference","title":"API Reference","text":""},{"location":"orchestration/#orchestrator","title":"Orchestrator","text":"Method Description <code>generate_from_description(description)</code> Generate orchestration from natural language <code>create_pattern_config(pattern_type, agents, ...)</code> Create configuration for a pattern <code>generate_code(config)</code> Generate executable code from config <code>list_patterns()</code> List all available patterns"},{"location":"orchestration/#patterntype","title":"PatternType","text":"Value Description <code>SUPERVISOR</code> Central coordinator pattern <code>DEBATE</code> Discussion and consensus pattern <code>VOTING</code> Democratic voting pattern <code>PIPELINE</code> Sequential processing pattern <code>MAP_REDUCE</code> Parallel processing pattern"},{"location":"orchestration/#pattern-classes","title":"Pattern Classes","text":"<p>Each pattern has a dedicated class with specific configuration options:</p> <ul> <li><code>SupervisorPattern</code> - Configure supervisor behavior and delegation rules</li> <li><code>DebatePattern</code> - Set debate rounds and moderation style</li> <li><code>VotingPattern</code> - Choose voting method and tie-breakers</li> <li><code>PipelinePattern</code> - Define stage transitions and error handling</li> <li><code>MapReducePattern</code> - Configure chunking and aggregation strategies</li> </ul>"},{"location":"tools/","title":"Tool Auto-Discovery &amp; Generation","text":"<p>The Tools module provides a registry of pre-built tools and the ability to generate custom tools from natural language descriptions.</p>"},{"location":"tools/#overview","title":"Overview","text":"<ul> <li>15+ pre-built tools across 10 categories</li> <li>Natural language tool generation - describe what you need, get working code</li> <li>Framework-agnostic - tools work with CrewAI, LangGraph, and other frameworks</li> <li>CLI support - generate and list tools from the command line</li> </ul>"},{"location":"tools/#cli-usage","title":"CLI Usage","text":""},{"location":"tools/#generate-a-tool","title":"Generate a Tool","text":"<p>Create tools from natural language descriptions:</p> <pre><code>multi-agent-generator --tool \"Create a tool to fetch stock prices from an API\"\n</code></pre> <p>Output:</p> <pre><code># Auto-generated tool: fetch_stock_prices\n# Category: api_integration\n# Description: Fetches stock prices from an API\n\nimport os\nimport requests\nfrom typing import Dict, Any\n\ndef fetch_stock_prices(symbol: str) -&gt; Dict[str, Any]:\n    \"\"\"Fetch stock prices for a given symbol.\"\"\"\n    api_key = os.getenv(\"STOCK_API_KEY\")\n    url = f\"https://api.stockdata.com/v1/quote?symbol={symbol}&amp;apikey={api_key}\"\n    response = requests.get(url)\n    return response.json()\n\n# Tool metadata\nTOOL_INFO = {\n    \"name\": \"fetch_stock_prices\",\n    \"description\": \"Fetches stock prices from an API\",\n    \"category\": \"api_integration\",\n    \"parameters\": {\"symbol\": {\"type\": \"string\", \"description\": \"Stock symbol\"}}\n}\n</code></pre>"},{"location":"tools/#save-to-file","title":"Save to File","text":"<pre><code>multi-agent-generator --tool \"Create a CSV parser tool\" --output csv_parser.py\n</code></pre>"},{"location":"tools/#list-all-tools","title":"List All Tools","text":"<pre><code>multi-agent-generator --list-tools\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udce6 All Available Tools:\n\n  [API_INTEGRATION]\n    \u2022 http_request: Make HTTP requests (GET, POST, PUT, DELETE) to any API endpoint.\n\n  [CODE_EXECUTION]\n    \u2022 python_executor: Execute Python code safely in an isolated environment.\n    \u2022 shell_command: Execute shell commands. Use with caution.\n\n  [COMMUNICATION]\n    \u2022 send_email: Send emails using SMTP. Requires email credentials.\n\n  [DATA_PROCESSING]\n    \u2022 csv_analyzer: Analyze a CSV file - get statistics, column info, and sample data.\n    \u2022 json_processor: Process and query JSON data using JSONPath expressions.\n\n  [DATABASE]\n    \u2022 sql_query: Execute SQL queries on SQLite databases.\n\n  [FILE_OPERATIONS]\n    \u2022 read_file: Read content from a file. Supports text files, JSON, CSV, etc.\n    \u2022 write_file: Write content to a file. Creates the file if it doesn't exist.\n    \u2022 list_directory: List all files and folders in a directory.\n\n  [MATH_CALCULATION]\n    \u2022 calculator: Perform mathematical calculations.\n\n  [TEXT_PROCESSING]\n    \u2022 text_summarizer: Summarize long text into key points.\n    \u2022 regex_extractor: Extract patterns from text using regular expressions.\n\n  [WEB_SEARCH]\n    \u2022 web_search: Search the web for information using a search query.\n    \u2022 wikipedia_search: Search Wikipedia for information on a topic.\n    \u2022 arxiv_search: Search arXiv for academic papers and research.\n</code></pre>"},{"location":"tools/#filter-by-category","title":"Filter by Category","text":"<pre><code>multi-agent-generator --list-tools --tool-category web_search\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udce6 Tools in category 'web_search':\n\n  \u2022 google_search: Search the web using Google\n    Parameters: ['query', 'num_results']\n  \u2022 web_scraper: Scrape content from web pages\n    Parameters: ['url', 'selector']\n</code></pre>"},{"location":"tools/#available-categories","title":"Available Categories","text":"<ul> <li><code>web_search</code> - Web search and scraping tools</li> <li><code>file_operations</code> - File system operations</li> <li><code>data_processing</code> - Data parsing and transformation</li> <li><code>code_execution</code> - Code runners and executors</li> <li><code>api_integration</code> - REST clients and webhooks</li> <li><code>database</code> - Database query tools</li> <li><code>communication</code> - Email, Slack, notifications</li> <li><code>math_calculation</code> - Calculators and statistics</li> <li><code>text_processing</code> - Text manipulation tools</li> <li><code>image_processing</code> - Image operations</li> <li><code>custom</code> - User-defined tools</li> </ul>"},{"location":"tools/#tool-registry","title":"Tool Registry","text":""},{"location":"tools/#browsing-tools","title":"Browsing Tools","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry, ToolCategory\n\nregistry = ToolRegistry()\n\n# List all categories\ncategories = [cat for cat in ToolCategory]\nprint(categories)\n# [ToolCategory.WEB_SEARCH, ToolCategory.FILE_OPERATIONS, ...]\n\n# Get tools by category\nweb_tools = registry.list_by_category(ToolCategory.WEB_SEARCH)\nfor tool in web_tools:\n    print(f\"{tool.name}: {tool.description}\")\n\n# List all available tools\nall_tools = registry.list_all()\n</code></pre>"},{"location":"tools/#pre-built-tool-categories","title":"Pre-built Tool Categories","text":"Category Tools Description Web Search google_search, web_scraper Search the web and scrape content File Operations read_file, write_file, list_directory File system operations Data Processing csv_parser, json_transformer Parse and transform data Code Execution python_executor, shell_runner Execute code snippets API Integration rest_client, webhook_handler HTTP requests and webhooks Database sql_query, document_store Database operations Communication email_sender, slack_notifier Send notifications Math calculator, statistics Mathematical operations Text Processing summarizer, translator Text manipulation Image Processing image_resizer, format_converter Image operations"},{"location":"tools/#getting-tool-details","title":"Getting Tool Details","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry\n\nregistry = ToolRegistry()\n\n# Get a specific tool\ntool = registry.get_tool(\"google_search\")\nprint(tool.name)\nprint(tool.description)\nprint(tool.parameters)\nprint(tool.code)\n</code></pre>"},{"location":"tools/#tool-generator","title":"Tool Generator","text":""},{"location":"tools/#generating-custom-tools","title":"Generating Custom Tools","text":"<p>Create tools from natural language descriptions:</p> <pre><code>from multi_agent_generator.tools import ToolGenerator\n\ngenerator = ToolGenerator()\n\n# Generate a tool from description\ntool = generator.generate_tool(\n    \"Create a tool that fetches weather data for a given city using an API\"\n)\n\nprint(tool.name)        # fetch_weather_data\nprint(tool.description) # Fetches weather data for a given city...\nprint(tool.code)        # Ready-to-use Python code\n</code></pre>"},{"location":"tools/#generated-tool-structure","title":"Generated Tool Structure","text":"<pre><code># Example generated tool code\ndef fetch_weather_data(city: str) -&gt; dict:\n    \"\"\"\n    Fetches weather data for a given city using an API.\n\n    Args:\n        city: The name of the city to fetch weather for\n\n    Returns:\n        Dictionary containing weather information\n    \"\"\"\n    import requests\n\n    api_key = os.getenv(\"WEATHER_API_KEY\")\n    url = f\"https://api.weatherapi.com/v1/current.json?key={api_key}&amp;q={city}\"\n\n    response = requests.get(url)\n    return response.json()\n</code></pre>"},{"location":"tools/#template-based-generation","title":"Template-Based Generation","text":"<p>For common patterns, use template-based generation:</p> <pre><code>from multi_agent_generator.tools import ToolGenerator\n\ngenerator = ToolGenerator()\n\n# Generate from template\ntool = generator.generate_from_template(\n    template=\"api_client\",\n    name=\"github_client\",\n    base_url=\"https://api.github.com\",\n    endpoints=[\"repos\", \"issues\", \"pulls\"]\n)\n</code></pre>"},{"location":"tools/#using-tools-with-agents","title":"Using Tools with Agents","text":""},{"location":"tools/#with-crewai","title":"With CrewAI","text":"<pre><code>from crewai import Agent\nfrom multi_agent_generator.tools import ToolRegistry\n\nregistry = ToolRegistry()\nsearch_tool = registry.get_tool(\"google_search\")\n\nagent = Agent(\n    role=\"Researcher\",\n    goal=\"Find information on topics\",\n    tools=[search_tool.to_crewai_tool()]\n)\n</code></pre>"},{"location":"tools/#with-langgraph","title":"With LangGraph","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry\n\nregistry = ToolRegistry()\ntools = registry.get_tools_by_category(\"web_search\")\n\n# Convert to LangChain tools\nlangchain_tools = [tool.to_langchain_tool() for tool in tools]\n</code></pre>"},{"location":"tools/#api-reference","title":"API Reference","text":""},{"location":"tools/#toolregistry","title":"ToolRegistry","text":"Method Description <code>get_categories()</code> List all tool categories <code>get_tools_by_category(category)</code> Get tools in a category <code>get_tool(name)</code> Get a specific tool by name <code>list_all_tools()</code> List all available tools <code>search_tools(query)</code> Search tools by keyword"},{"location":"tools/#toolgenerator","title":"ToolGenerator","text":"Method Description <code>generate_tool(description)</code> Generate tool from natural language <code>generate_from_template(template, **kwargs)</code> Generate from predefined template <code>validate_tool(tool)</code> Validate generated tool code"},{"location":"tools/#tooldefinition","title":"ToolDefinition","text":"Property Type Description <code>name</code> str Tool name <code>description</code> str Tool description <code>category</code> ToolCategory Tool category <code>parameters</code> dict Input parameters schema <code>returns</code> str Return type description <code>code</code> str Python implementation"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#command-line-interface","title":"Command Line Interface","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<p>Generate agent code with OpenAI (default):</p> <pre><code>multi-agent-generator \"I need a research assistant that summarizes papers and answers questions\" --framework crewai\n</code></pre>"},{"location":"usage/#specifying-a-provider","title":"Specifying a Provider","text":"<p>Using WatsonX:</p> <pre><code>multi-agent-generator \"I need a research assistant\" --framework crewai --provider watsonx\n</code></pre> <p>Using Ollama locally:</p> <pre><code>multi-agent-generator \"Build me a ReAct assistant for customer support\" --framework react-lcel --provider ollama\n</code></pre>"},{"location":"usage/#using-agno-framework","title":"Using Agno Framework","text":"<pre><code>multi-agent-generator \"build a researcher and writer\" --framework agno --provider openai --output agno.py --format code\n</code></pre>"},{"location":"usage/#saving-output","title":"Saving Output","text":"<p>Save to a Python file:</p> <pre><code>multi-agent-generator \"I need a team to create viral social media content\" --framework langgraph --output social_team.py\n</code></pre>"},{"location":"usage/#output-formats","title":"Output Formats","text":"<p>Get JSON configuration only:</p> <pre><code>multi-agent-generator \"I need a team to analyze customer data\" --framework react --format json\n</code></pre> <p>Get code only:</p> <pre><code>multi-agent-generator \"Build a support team\" --framework crewai --format code\n</code></pre> <p>Get both (default):</p> <pre><code>multi-agent-generator \"Build a support team\" --framework crewai --format both\n</code></pre>"},{"location":"usage/#cli-options","title":"CLI Options","text":"Option Description Default <code>--framework</code> Target framework (crewai, crewai-flow, langgraph, react, react-lcel, agno) crewai <code>--provider</code> LLM provider (openai, watsonx, ollama, anthropic) openai <code>--output</code> Output file path stdout <code>--format</code> Output format (code, json, both) both <code>--list-tools</code> List all available tools - <code>--tool-category</code> Filter tools by category - <code>--evaluate</code> Enable evaluation mode - <code>--query</code> Query for evaluation - <code>--response</code> Response to evaluate - <code>--expected</code> Expected output (optional) - <code>--threshold</code> Minimum passing score 0.7 <code>--orchestrate</code> Get orchestration pattern suggestion - <code>--list-patterns</code> List orchestration patterns - <code>--pattern</code> Generate code for specific pattern - <code>--num-agents</code> Number of agents for orchestration 3"},{"location":"usage/#tool-generation-via-cli","title":"Tool Generation via CLI","text":"<p>Generate custom tools from natural language descriptions:</p> <pre><code># Generate a tool from description\nmulti-agent-generator --tool \"Create a tool to fetch weather data for a city\"\n</code></pre> <p>Output:</p> <pre><code># Auto-generated tool: fetch_weather_data\n# Category: api_integration\n# Description: Fetches weather data for a given city\n\nimport os\nimport requests\nfrom typing import Dict, Any\n\ndef fetch_weather_data(city: str) -&gt; Dict[str, Any]:\n    \"\"\"Fetch weather data for a city.\"\"\"\n    api_key = os.getenv(\"WEATHER_API_KEY\")\n    url = f\"https://api.weatherapi.com/v1/current.json?key={api_key}&amp;q={city}\"\n    response = requests.get(url)\n    return response.json()\n</code></pre>"},{"location":"usage/#list-available-tools","title":"List Available Tools","text":"<pre><code># List all tools\nmulti-agent-generator --list-tools\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udce6 All Available Tools:\n\n  [API_INTEGRATION]\n    \u2022 http_request: Make HTTP requests (GET, POST, PUT, DELETE) to any API endpoint.\n\n  [CODE_EXECUTION]\n    \u2022 python_executor: Execute Python code safely in an isolated environment.\n    \u2022 shell_command: Execute shell commands. Use with caution.\n\n  [FILE_OPERATIONS]\n    \u2022 read_file: Read content from a file. Supports text files, JSON, CSV, etc.\n    \u2022 write_file: Write content to a file. Creates the file if it doesn't exist.\n    \u2022 list_directory: List all files and folders in a directory.\n    ...\n</code></pre>"},{"location":"usage/#filter-by-category","title":"Filter by Category","text":"<pre><code>multi-agent-generator --list-tools --tool-category api_integration\n</code></pre>"},{"location":"usage/#evaluation-via-cli","title":"Evaluation via CLI","text":"<p>Evaluate agent output quality directly from the command line:</p>"},{"location":"usage/#basic-evaluation","title":"Basic Evaluation","text":"<pre><code>multi-agent-generator --evaluate \\\n  --query \"What is machine learning?\" \\\n  --response \"Machine learning is a subset of AI that enables systems to learn from data\"\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udcca Evaluating agent output...\n\nEvaluation Results: \u2705 PASSED\n==================================================\nQuery: What is machine learning?\nResponse: Machine learning is a subset of AI that enables systems to learn from data\n\nMetrics:\n  \u2022 Relevance:        1.00\n  \u2022 Completeness:     0.50\n  \u2022 Coherence:        0.80\n  \u2022 Accuracy:         0.70\n  \u2022 Task Completion:  0.70\n  \u2022 Response Time:    0.00ms\n  \u2022 Token Count:      18\n\nOverall Score: 0.740 (threshold: 0.7)\n</code></pre>"},{"location":"usage/#with-expected-output","title":"With Expected Output","text":"<p>Provide expected output for accuracy comparison:</p> <pre><code>multi-agent-generator --evaluate \\\n  --query \"Summarize AI\" \\\n  --response \"AI is artificial intelligence\" \\\n  --expected \"Artificial intelligence is technology that mimics human cognition\" \\\n  --threshold 0.8\n</code></pre>"},{"location":"usage/#save-results-to-file","title":"Save Results to File","text":"<pre><code>multi-agent-generator --evaluate \\\n  --query \"Test query\" \\\n  --response \"Test response\" \\\n  --output evaluation_results.json\n</code></pre>"},{"location":"usage/#orchestration-via-cli","title":"Orchestration via CLI","text":"<p>Create orchestrated multi-agent systems from the command line:</p>"},{"location":"usage/#list-available-patterns","title":"List Available Patterns","text":"<pre><code>multi-agent-generator --list-patterns\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udd04 Available Orchestration Patterns:\n\n  [SUPERVISOR PATTERN]\n    Description: A supervisor agent coordinates and delegates tasks to specialized worker agents\n    Use Cases:\n      \u2022 Project management workflows\n      \u2022 Quality assurance processes\n      \u2022 Customer service escalation\n\n  [DEBATE PATTERN]\n    Description: Multiple agents argue different perspectives and reach consensus\n    Use Cases:\n      \u2022 Decision making processes\n      \u2022 Fact checking and verification\n      \u2022 Brainstorming sessions\n  ...\n</code></pre>"},{"location":"usage/#get-pattern-suggestion","title":"Get Pattern Suggestion","text":"<p>Describe your needs and get a recommended pattern:</p> <pre><code>multi-agent-generator --orchestrate \"I need agents to work together on a document, each reviewing the previous agent's work\"\n</code></pre> <p>Output:</p> <pre><code>\ud83d\udd04 Analyzing task description...\n   \"I need agents to work together on a document, each reviewing the previous agent's work\"\n\n\ud83d\udccc Recommended pattern: pipeline\n\n\ud83c\udfd7\ufe0f  Generating pipeline orchestration code for langgraph...\n\n# Generated LangGraph Pipeline Code\nfrom langgraph.graph import StateGraph, END\n...\n</code></pre>"},{"location":"usage/#generate-code-for-specific-pattern","title":"Generate Code for Specific Pattern","text":"<pre><code># Generate supervisor pattern with LangGraph\nmulti-agent-generator --pattern supervisor --framework langgraph --output supervisor_agents.py\n\n# Generate debate pattern with CrewAI\nmulti-agent-generator --pattern debate --framework crewai --num-agents 3\n\n# Generate voting pattern with 5 agents\nmulti-agent-generator --pattern voting --num-agents 5 --framework langgraph\n</code></pre>"},{"location":"usage/#streamlit-ui","title":"Streamlit UI","text":"<p>Launch the interactive web interface:</p> <pre><code>streamlit run streamlit_app.py\n</code></pre>"},{"location":"usage/#available-pages","title":"Available Pages","text":"<ol> <li>Agent Generator - Generate agent code from natural language descriptions</li> <li>Tool Discovery - Browse pre-built tools and create custom ones</li> <li>Orchestration Patterns - Configure multi-agent coordination patterns</li> <li>Evaluation &amp; Testing - Generate tests and evaluate agent outputs</li> </ol>"},{"location":"usage/#python-api","title":"Python API","text":""},{"location":"usage/#basic-code-generation","title":"Basic Code Generation","text":"<pre><code>from multi_agent_generator import generate_agents\n\n# Generate CrewAI agents\nresult = generate_agents(\n    prompt=\"I need a research team with a lead and two specialists\",\n    framework=\"crewai\",\n    provider=\"openai\"\n)\n\nprint(result[\"code\"])\nprint(result[\"config\"])\n</code></pre>"},{"location":"usage/#tool-discovery","title":"Tool Discovery","text":"<pre><code>from multi_agent_generator.tools import ToolRegistry, ToolGenerator, ToolCategory\n\n# Browse pre-built tools\nregistry = ToolRegistry()\ncategories = [cat for cat in ToolCategory]\nweb_tools = registry.list_by_category(ToolCategory.WEB_SEARCH)\n\n# Generate custom tools\ngenerator = ToolGenerator()\ntool = generator.generate_from_description(\"Create a tool that fetches weather data\")\nprint(tool.code)\n</code></pre>"},{"location":"usage/#orchestration-patterns","title":"Orchestration Patterns","text":"<pre><code>from multi_agent_generator.orchestration import Orchestrator, PatternType\n\norchestrator = Orchestrator()\n\n# Generate from description\nresult = orchestrator.generate_from_description(\n    \"I need a supervisor managing a team of specialists\"\n)\n\n# Or configure manually\nconfig = orchestrator.create_pattern_config(\n    pattern_type=PatternType.SUPERVISOR,\n    agents=[\"researcher\", \"writer\", \"reviewer\"],\n    task_description=\"Analyze market trends\"\n)\n</code></pre>"},{"location":"usage/#evaluation-testing","title":"Evaluation &amp; Testing","text":"<pre><code>from multi_agent_generator.evaluation import TestGenerator, AgentEvaluator\n\n# Generate test suites\ntest_gen = TestGenerator()\ntest_suite = test_gen.generate_test_suite(\n    agent_config=your_config,\n    test_types=[\"unit\", \"integration\"]\n)\ntest_suite.save(\"tests/\")\n\n# Evaluate outputs\nevaluator = AgentEvaluator()\nresult = evaluator.evaluate(\n    agent_output=\"The analysis shows...\",\n    expected_output=\"Market trends indicate...\",\n    task_description=\"Analyze Q4 sales\"\n)\nprint(result.overall_score)\n</code></pre>"},{"location":"frameworks/agno/","title":"Agno Framework","text":"<p>Agno coordinates and orchestrates role-playing autonomous AI agents. Each agent has:</p> <ul> <li>Name and Role: what they do</li> <li>Goal: their objective</li> <li>Backstory: context</li> <li>Tools: available abilities</li> </ul> <p>Tasks are assigned to agents with expected outputs.</p>"},{"location":"frameworks/agno/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Research AI trends and write a summary\" --framework agno\n</code></pre>"},{"location":"frameworks/agno/#produces-agents-like","title":"Produces agents like:","text":"<pre><code>{\n  \"model_id\": \"gpt-4o\",\n  \"process\": \"sequential\",\n  \"agents\": [\n    {\n      \"name\": \"research_specialist\",\n      \"role\": \"Research Specialist\",\n      \"goal\": \"Gather AI research trends\",\n      \"backstory\": \"Expert in sourcing and aggregating technology news\",\n      \"tools\": [\"DuckDuckGoTools\", \"Newspaper4kTools\"]\n    },\n    {\n      \"name\": \"writer\",\n      \"role\": \"Content Writer\",\n      \"goal\": \"Write a clear summary\",\n      \"backstory\": \"Skilled at concise technical writing\",\n      \"tools\": []\n    }\n  ],\n  \"tasks\": [\n    {\n      \"name\": \"research_task\",\n      \"description\": \"Find recent AI trends across news and blogs\",\n      \"agent\": \"research_specialist\",\n      \"expected_output\": \"Bullet list of trends with links\"\n    },\n    {\n      \"name\": \"writing_task\",\n      \"description\": \"Summarize the trends for a general audience\",\n      \"agent\": \"writer\",\n      \"expected_output\": \"400-word Markdown summary\"\n    }\n  ]\n}\n</code></pre>"},{"location":"frameworks/crewai-flow/","title":"CrewAI Flow","text":"<p>CrewAI Flow extends CrewAI with event-driven workflows. It enables sequential, parallel, and conditional task execution with state management.</p>"},{"location":"frameworks/crewai-flow/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Analyze customer reviews and generate insights\" --framework crewai-flow\n</code></pre>"},{"location":"frameworks/crewai-flow/#this-produces","title":"This produces:","text":"<ul> <li> <p>Specialized agents (e.g., Data Collector, Data Analyst, Writer)</p> </li> <li> <p>Sequential flow: collect \u2192 analyze \u2192 summarize</p> </li> <li> <p>Task delegation and transitions defined</p> </li> </ul>"},{"location":"frameworks/crewai/","title":"CrewAI Framework","text":"<p>CrewAI orchestrates role-playing autonomous AI agents. Each agent has:</p> <ul> <li>Role: what they do</li> <li>Goal: their objective</li> <li>Backstory: context</li> <li>Tools: available abilities</li> </ul> <p>Tasks are assigned to agents with expected outputs.</p>"},{"location":"frameworks/crewai/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Research AI trends and write a summary\" --framework crewai\n</code></pre>"},{"location":"frameworks/crewai/#produces-agents-like","title":"Produces agents like:","text":"<pre><code>{\n  \"agents\": [\n    {\n      \"name\": \"research_specialist\",\n      \"role\": \"Research Specialist\",\n      \"goal\": \"Gather AI research trends\",\n      \"tools\": [\"search_tool\"]\n    },\n    {\n      \"name\": \"writer\",\n      \"role\": \"Content Writer\",\n      \"goal\": \"Write a summary\",\n      \"tools\": [\"editor_tool\"]\n    }\n  ],\n  \"tasks\": [...]\n}\n</code></pre>"},{"location":"frameworks/langgraph/","title":"LangGraph Framework","text":"<p>LangGraph is LangChain's framework for stateful, multi-actor applications. It represents workflows as directed graphs with:</p> <ul> <li>Nodes: agents, tools, or operations</li> <li>Edges: control/data flow</li> <li>Conditions: define branching behavior</li> </ul>"},{"location":"frameworks/langgraph/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Build me a LangGraph workflow for customer support\" --framework langgraph\n</code></pre>"},{"location":"frameworks/langgraph/#generates-a-graph-like","title":"Generates a graph like:","text":"<pre><code>{\n  \"agents\": [{ \"name\": \"support_agent\", \"llm\": \"gpt-4.1-mini\" }],\n  \"nodes\": [\n    { \"name\": \"greet_customer\", \"agent\": \"support_agent\" },\n    { \"name\": \"resolve_issue\", \"agent\": \"support_agent\" }\n  ],\n  \"edges\": [\n    { \"source\": \"greet_customer\", \"target\": \"resolve_issue\" }\n  ]\n}\n</code></pre>"},{"location":"frameworks/react-lcel/","title":"ReAct (LCEL)","text":"<p>ReAct (Reasoning + Acting) with LangChain Expression Language (LCEL). Supports multi-step reasoning, tool usage, and history tracking.</p>"},{"location":"frameworks/react-lcel/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Find AI papers and summarize them\" --framework react-lcel\n</code></pre>"},{"location":"frameworks/react-lcel/#generated-agent-includes","title":"Generated agent includes:","text":"<ul> <li> <p>Multi-step reasoning traces</p> </li> <li> <p>Tool calls with inputs/outputs</p> </li> <li> <p>LangChain Expression Language chain</p> </li> </ul>"},{"location":"frameworks/react-lcel/#example-snippet","title":"Example Snippet","text":"<pre><code>chain = (\n    {\"input\": RunnablePassthrough(), \"history\": RunnablePassthrough()}\n    | react_prompt\n    | llm\n    | StrOutputParser()\n)\n</code></pre>"},{"location":"frameworks/react/","title":"ReAct (Classic)","text":"<p>ReAct (Reasoning + Acting) combines thoughts + actions. The agent reasons about a problem, then decides when to call a tool.</p>"},{"location":"frameworks/react/#example","title":"Example","text":"<pre><code>multi-agent-generator \"Answer math questions using a calculator tool\" --framework react\n</code></pre>"},{"location":"frameworks/react/#produces","title":"Produces:","text":"<ul> <li> <p>An agent with reasoning + acting steps</p> </li> <li> <p>Tool definitions with parameters</p> </li> <li> <p>ReAct-style execution loop</p> </li> </ul>"}]}